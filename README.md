# Product-recommender-app

A full stack AI powered web app that gives product recommendations based on user query.

## ğŸ’» Run Locally

**Prerequisites:**

- Python installed
- A [Pinecone](https://www.pinecone.io/) account
- A Google AI API key from [Google AI Studio](https://aistudio.google.com/app/api-keys)

1. Clone the project and install dependencies

```bash
git clone https://github.com/Dilpreet-singh-13/Product-recommender-app.git
cd Product-recommender-app
# Install the uv pacaage manger
pip install uv
# Create a virtual environment
uv venv
.venv\Scripts\activate On Unix or MacOS use `source .venv/bin/activate`
# Install dependencies
uv sync
```

2. Initial Setup

```bash
uv run manage.py makemigrations
uv run manage.py migrate
```

3. Setup environment variables

```bash
cp .env.example .env # Edit .env with your API keys
```

4. Data Related scripts

```bash
cd scripts
uv run preprocess_data.py
cd ..

# Populate local and cloud database
uv run manage.py load_products
uv run manage.py upsert_to_pinecone
```

5. Run the local web server

```bash
uv run manage.py runserver
```

Then visit `http://127.0.0.1:8000/recommend/`

## ğŸ” How does it work

1. The given dataset is processed and stored into a csv. Done via the `preprocess_data.py` script.
2. Data is loaded into the local db via `load_products` command.
    - SQLite is used as the local db for simplicity. For actual use consider using another db like Postgress
3. Embeddings are generated and stored at a serverless **Pinecone vector db**. This is done via the `upsert_to_pinecone`
   command.
    - We use the free tier `ss` model for embeddings, it's trained on very large amounts of data to give rich contextual
      embeddings
    - Embedding size: `1024`
    - We only upsert relevant data onto pinecone, the rest is kept is local db for fast retrival. This keeps the usage
      and limits of the free tier in check.
4. The user enters a "search prompt" about what they want to buy.
5. We retrieve the top 5 most relevant products from our database using Pinecone's **semantic search**
    - We use `cosine similarity` to match relevant products.
    - The user query is also converted into a dense vector, and then it's matched with product embeddings.
6. The product info is displayed to the user with a creative description.
    - The creative description is generated by an LLM based on all the product info given by us.

## ğŸ“ project Structure

*Only shows important files and directories*

```
Product-recommender-app/
â”œâ”€â”€ .env.example                      # Example environment variables file
â”‚
â”œâ”€â”€ core/                             # Django core project (contains settings, urls, wsgi, etc.)
â”‚
â”œâ”€â”€ data/                             # Data directory
â”‚   â”œâ”€â”€ product_data.csv              # Original raw dataset
â”‚   â””â”€â”€ cleaned_data.csv              # Preprocessed / cleaned dataset
â”‚
â”œâ”€â”€ recommendations/                  # Main Django app for recommendation logic
â”‚   â”œâ”€â”€ management/
â”‚   â”‚   â””â”€â”€ commands/
â”‚   â”‚       â”œâ”€â”€ load_products.py      # Populates local DB with preprocessed data
â”‚   â”‚       â””â”€â”€ upsert_to_pinecone.py # Uploads data & embeddings to Pinecone vector DB
â”‚   â”‚
â”‚   â”œâ”€â”€ templates/                    # Contains frontend templates (HTML, etc.)
â”‚   â””â”€â”€ ...                           # Models, views, serializers, etc.
â”‚
â”œâ”€â”€ scripts/                          # Standalone utility scripts
â”‚    â””â”€â”€ preprocess_data.py           # Script to clean and preprocess raw data
â”‚ 
â””â”€â”€ notebooks/
     â””â”€â”€ data_pre_processing.ipynb    # Preprocessing notebook
     â””â”€â”€ data_visualization.ipynb     # Data visualizations notebook         
```